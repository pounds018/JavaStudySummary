## 1. NIO 与 零拷贝:  

1. 简介: `零拷贝就是一种避免cpu将数据从一块存储拷贝到另外一块存储的技术,零拷贝指的是没有cpu参与拷贝数据`  
   - 零拷贝是网络编程的关键,很多性能优化都离不开零拷贝,利用零拷贝减少不必要的数据拷贝,从而优化网络编程效率  
   - 零拷贝指的是从操作系统的角度来说,整个操作系统中有且只有一份数据,此外没有与之重复的数据,通过MDA和SG-DMA技术减少cpu拷贝的开销
   - java程序中,常用的零拷贝有mmap(内存映射) 和 sendFile()
   
2. 零拷贝的好处:  
   - 减少或者避免不必要的cpu数据拷贝,从而释放cpu去执行其他任务  
   - 零拷贝机制能减少用户空间和操作系统内核空间的上下文切换次数
   - 减少内存的占用  
   
3. 内核空间和用户空间:  
   ![内核和用户空间](../../_media/chapter13_Netty/2_零拷贝/内核和用户空间.png)  

   为了避免用户进程直接操作系统内核, 保证系统内核安全, 操作系统将内存(虚拟内存) 划分为两部分, 分别是 `内核空间` 和 `用户空间`

   1. 用户空间: 

      每个进程都有一个独立的用户空间, 对应的进程处于用户态, 操作系统规定, 用户态不能直接访问内核空间中的数据, 也不能直接调用内核函数. `要调用内核函数必须通过系统接口, 将进程切换到内核态, 才能想内核发出指令, 完成调用`

   2. 内核空间:

      操作系统的核心是内核, 独立于普通的应用程序, 可以访问受保护的内核空间, 也有底层硬件设备的权限. 内核空间总是驻留于内存中, 他是为操作系统保留的

4. 缓冲区和虚拟内存:  
   ![缓冲区和虚拟内存](../../_media/chapter13_Netty/2_零拷贝/缓冲区和虚拟内存.png)  
   - `直接内存访问技术(Direct Memory Access -DMA)`: 在进行I/O设备和内存数据传输的时候,数据传输工作全部交给I/O硬件设备中的DMA技术,
     从而cpu不需要参与将数据从I/O设备传输到内存这一过程数据的拷贝.  
   - `缓冲区`:  内核空间存放I/O过程中需要传输数据的区域  
   - `虚拟内存`:  


## 2. 传统i/o看数据拷贝流程:  
1. 以下面这个文件传输为例,了解传统I/O过程中数据拷贝的过程:  
   ![内核和用户空间](../../_media/chapter13_Netty/2_零拷贝/传统文件传输代码.png)  
   - 传统I/O文件数据拷贝流程:  
     ![过程图](../../_media/chapter13_Netty/2_零拷贝/传统文件传输过程图.png)
     ![时序图](../../_media/chapter13_Netty/2_零拷贝/传统文件传输拷贝流程时序图.png)  
     过程总结:
      - 上下文切换: 一共发生了四次上下文切换
         1. 向操作系统发起read请求,`从用户空间切换到内核空间`  
         2. read请求完成,向用户返回数据,`从内核空间切换到用户空间`  
         3. 向操作系统发起write请求, `从用户空间切换到内核空间`  
         4. write请求完成,继续执行用户进程其他任务, `从内核空间切换到用户空间`  
      - 数据拷贝:  一共发生四次拷贝
         1. I/O硬件向内核空间缓冲区的DMA拷贝
         2. 内核缓冲区向用户缓冲区的cpu拷贝  
         3. 用户空间缓冲区向socket缓冲区的cpu拷贝  
         4. socket缓冲区向网卡的DMA拷贝
   

## 3. 优化传统I/O实现零拷贝:  
1. 使用mmap()调用优化掉一次`cpu拷贝`:  
   1. mmap()调用的效果: 通过内存映射,将内核空间的地址映射到用户空间,`达到内核空间和用户空间共享数据的效果`,从而减少一次从`内核空间拷贝数据到用户空间的cpu拷贝开销`  
      ![mmap()时序图](../../_media/chapter13_Netty/2_零拷贝/mmap.png)  
      ![mmap()流程图](../../_media/chapter13_Netty/2_零拷贝/mmap流程图.png)  
      过程总结:  
      - 四次上下文切换:  
         1. 向操作系统发起mmap()调用,`从用户空间切换到内核空间`
         2. mmap()调用完成,返回用户空间执行用户进程后续操作,`从内核空间切换到用户空间`
         3. 向操作系统发起write请求, `从用户空间切换到内核空间`
         4. write请求完成,继续执行用户进程其他任务, `从内核空间切换到用户空间` 
      - 三次数据拷贝:  
         1. I/O硬件向内核空间缓冲区的DMA拷贝
         2. 由于内核空间和用户空间共享数据, `无需再像用户空间复制数据`,在write的时候`直接`从内核缓冲区通过cpu拷贝数据到socket缓冲区
         4. socket缓冲区向网卡的DMA拷贝
   
2. 使用sendFile()替换read,write函数, `优化掉两次上下文切换`  
   1. sendFile函数: 
      ```c++
         #include<sys/socket.h>
         ssize_t sendfile(int out_fd, int in_fd, off_t *offset,size_t count);
      ```
      - 解释: out_fd是目的文件描述符,in_fd是源文件描述符号,offset是源文件的偏移量,count是需要处理的长度
      - sendfile的作用: 
         1. 替换write和read函数,减少两次上下文切换
         2. 在调用sendfile函数的时候,由用户空间切换到内核空间之后,直接在内核空间使用cpu拷贝,向socket缓冲区复制数据,处理完成之后再切换到用户空间  
      
      ![mmap()流程图](../../_media/chapter13_Netty/2_零拷贝/sendFile.png)   
      ![mmap()流程图](../../_media/chapter13_Netty/2_零拷贝/send.png)   
      - 总结:  
         - 两次上下文切换:  
            1. 调用sendfile函数,从用户空间切换到内核空间  
            2. sendfile处理完成,从内核空间切换到用户空间,继续执行用户进程剩下的操作.
         - 三次数据拷贝
            1. I/O硬件通过DMA技术,将数据拷贝至内核空间缓冲区  
            2. 用户进程调用sendFile函数之后,`数据与用户空间缓冲区不再产生联系`, 直接从内核缓冲区通过cpu拷贝数据到socket缓冲区
            3. socket缓冲向网卡的DMA拷贝  
   
3. 优化sendfile函数,实现真正的零拷贝,`没有cpu拷贝`:  
   - 如果网卡支持SG-DMA(The Scatter-Gather Direct Memory Access)技术,就可以进一步`减少`数据从内核空间经过cpu拷贝到socket缓冲区的开销.原来从内核空间缓冲区,通过cpu拷贝数据到
     socket缓冲区的过程还在,但是只有关于数据去向和长度信息的描述符才会被附加到套接字缓冲区,这部分的开销可以忽略不计.  
     ![mmap()流程图](../../_media/chapter13_Netty/2_零拷贝/真正的零拷贝.png)   
     ![mmap()流程图](../../_media/chapter13_Netty/2_零拷贝/真正的零拷贝过程图-55.png)   
     - 总结:  
        - 2次上下文切换:
            1. 调用sendfile函数,从用户空间切换到内核空间
            2. sendfile处理完成,从内核空间切换到用户空间,继续执行用户进程剩下的操作. 
        - 2次数据拷贝:  
            1. I/O硬件通过DMA技术,将数据拷贝至内核空间缓冲区  
            2. 不再将内存缓冲区的数据复制到socket缓冲区,只是将少部分数据去向描述符和数据长度描述符传递给socket缓冲区,通过SG-DMA技术直接将数据拷贝到网卡中  


## 4. JAVA NIO中的零拷贝:
客户端demo:  
```java
    package cn.pounds.nio.zerocopy;
    
    import java.io.FileInputStream;
    import java.io.IOException;
    import java.net.InetSocketAddress;
    import java.nio.channels.FileChannel;
    import java.nio.channels.SocketChannel;
    
    /**
     * @Date 2021/5/9 12:43
     * @Author by pounds
     * @Description Nio中的零拷贝
     */
    public class NioClient {
        public static void main(String[] args) throws IOException {
            SocketChannel client = SocketChannel.open();
            client.connect(new InetSocketAddress("localhost",7001));
            String file = "protoc-3.6.1-win32.zip";
    
            FileChannel fileChannel = new FileInputStream(file).getChannel();
    
            long startTime = System.currentTimeMillis();
    
            // windows系统中,transferTo方法每次只能传输8m,需要分段传输,linux系统则不需要,下面这个写法是linux的写法\
            // transferTo 就是使用的零拷贝
            fileChannel.transferTo(0,fileChannel.size(),client);
    
            System.out.println(String.format("总共耗时 %s ",System.currentTimeMillis() - startTime));
    
        }
    }
```
服务端demo:  
```java
package cn.pounds.nio.zerocopy;

import java.io.IOException;
import java.net.InetSocketAddress;
import java.nio.ByteBuffer;
import java.nio.channels.ServerSocketChannel;
import java.nio.channels.SocketChannel;

/**
 * @Date 2021/5/9 12:35
 * @Author by pounds
 * @Description Nio中的零拷贝
 */
public class NioServer {
    public static void main(String[] args) throws IOException {
        ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();
        serverSocketChannel.socket().bind(new InetSocketAddress("127.0.0.1",7001));

        ByteBuffer byteBuffer = ByteBuffer.allocate(4096);

        while (true){
            SocketChannel socketChannel = serverSocketChannel.accept();
            int readCount = 0;
            while (-1 != readCount){
                try {
                    readCount = socketChannel.read(byteBuffer);
                }catch (Exception e){
                    e.printStackTrace();
                }
                // 重新读
                byteBuffer.rewind();
            }
        }
    }
}
```

## 5. 操作系统配置支撑百万级别的并发连接:

1. 相关概念:

   `文件描述符`: 

   在linux系统中, 万物皆文件, socket也不例外, socket也是用文件来表示的. 程序在读写文件的时候,首先需要打开该文件, 打开的过程其实本质就是在进程与文件之间建立连接, 句柄的作用就是唯一标识此文件. 后面对文件读写时, 句柄就表示该文件. 关闭文件的过程本质上就是释放文件句柄的过程.`文件句柄` 也叫`文件描述符`.

   `文件描述符` 是系统内核为了高效管理已被打开的文件所创建的索引, `文件描述符是一个非负整数`.

   linux系统中 , 可以通过下面这个命令来查看一个进程能够打开的最大文件句柄数量

   ```shell
   ulimit -n
   // ulimit命令是用来显示和`临时`修改当前用户进程一些基础限制的命令, -n选项用于应用或设置当前句柄数量限制值, linux系统`单个进程最大FD数量`默认为1024
   ```

   > 通常情况下, 1024个FD是够用了的, 但是如果要实现百万级的并发连接肯定是不够用的

2. 修改FD配置以实现百万级并发连接:

   - 文件句柄全局配置, 全局配置文件路径 `/etc/sysctl.conf`

     ```shell
     # 参考配置
     fs.file-max=2048000
     fs.nr-open=1024000
     ```

     `fs.file-max`: 表示整个操作系统能够打开的文件描述符数量

     `fs.nr-open`: 表示单个进程可以打开的文件描述符数量, `/etc/security/limit.conf`里面的nofile配置项是收到这个配置限制的

   - 一次性配置修改:

     ```shell
     ulimit -SHn 1000000
     ```

     `-S` : 表示软上限, 超过这个值操作系统会告警, 还是可以继续创建连接.

     `-H` : 表示硬上限, 达到这个值就不能创建连接了.

   - 永久生效, 修改或者添加`/etc/security/limit.conf`文件里面,如下:

     ```shell
     *　soft nofile 1000000
     *　hard nofile 1000000　
     ```

     `soft` : 表示软上限, 超过这个值操作系统会告警, 还是可以继续创建连接.

     `soft` : 表示硬上限, 达到这个值就不能创建连接了.